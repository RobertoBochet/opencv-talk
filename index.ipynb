{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 style=\"text-align:center; font-size: 2em;\">Python Course 2020</h1>\n",
    "<h2 style=\"text-align:center; font-size: 1.6em;\">Few words about OpenCV2</h2>\n",
    "<h3 style=\"text-align:center; font-size: 1.1em;\">(Just an excuse to see how to code in Python)</h3>\n",
    "\n",
    "<img style=\"width:25em;\" src=\"https://static.poul.org/assets/logo/logo_text_g.svg\" alt=\"POuL logo\"/>\n",
    "\n",
    "<p style=\"text-align: center;\">Roberto Bochet &lt;avrdudo@poul.org&gt;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is OpenCV2?\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/32/OpenCV_Logo_with_text_svg_version.svg\" width=\"150\"/>\n",
    "\n",
    "It is an **open source** library for real-time **computer vision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/OfxOpenCV.png\" width=\"300\"/>\n",
    "\n",
    "*Credits [Wikimedia](https://commons.wikimedia.org/wiki/File:OfxOpenCV.png) / Screenshot of openFrameworks / [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Let's see how to use a library!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Very first thing!\n",
    "\n",
    "## Retrieve the documentations\n",
    "\n",
    "- [Site](https://opencv.org/)\n",
    "- [Tutorial *4.3.0*](https://docs.opencv.org/4.3.0/d6/d00/tutorial_py_root.html)\n",
    "- [Documentation *4.3.0*](https://docs.opencv.org/4.3.0/)\n",
    "- [Wiki](https://github.com/opencv/opencv/wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to use a library in python the first thing we have to do is importing the package.\n",
    "\n",
    "It is conventional to import `OpenCV2` with the alias `cv`, obviously it is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/example.jpg\", cv.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [`cv.imread`](https://docs.opencv.org/4.3.0/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56) to load an image.\n",
    "\n",
    "The first argument is the path of the image, the second one tells opencv how to load the image, where the most commonly used values are [`cv.IMREAD_COLOR`](https://docs.opencv.org/4.3.0/d4/da8/group__imgcodecs.html#gga61d9b0126a3e57d9277ac48327799c80af660544735200cbe942eea09232eb822), [`cv.IMREAD_GRAYSCALE`](https://docs.opencv.org/4.3.0/d4/da8/group__imgcodecs.html#gga61d9b0126a3e57d9277ac48327799c80ae29981cfc153d3b0cef5c0daeedd2125) or [`cv.IMREAD_UNCHANGED`](https://docs.opencv.org/4.3.0/d4/da8/group__imgcodecs.html#gga61d9b0126a3e57d9277ac48327799c80aeddd67043ed0df14f9d9a4e66d2b0708).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does `cv.imread` produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imread` returns a [`NumPy`](https://numpy.org/) [`ndarray`](https://numpy.org/doc/stable/reference/arrays.ndarray.html).\n",
    "\n",
    "[`NumPy`](https://numpy.org/) is a library which is part of [`SciPy`](https://www.scipy.org/) project, with the aim of providing a smart and powerful system to work with multidimensional matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ndim` method of NumPy array returns the number of matrix dimensions. \n",
    "\n",
    "Our matrix has `3` dimensions, this makes sense: two dimensions are the height and the width of the image, the third is represented by color's channels of each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape` method returns a tuple of the size of the matrix of each dimension.\n",
    "\n",
    "The first two are image's height and width, `3` is the number of color's channels. Does **RGB** ring a bell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last interesting thing about NumPy's array.\n",
    "\n",
    "`dtype` method returns the type of data composing the array.\n",
    "\n",
    "\n",
    "So, in our image each channel of each pixel is identified by an `unsigned integer` of `8bit`, thus the image's color depth is `8bit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little question: What about the `shape` of a `grayscale` image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imread(\"./images/example.jpg\", cv.IMREAD_GRAYSCALE).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix has only two dimensions, because each pixel is characterized by only one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the basis to understand what we see above, but it is not very helpful to understand \"what\" we are seeing.\n",
    "\n",
    "Let's try to visualize the image in a more useful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cv.imshow(\"Example image\",img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "[`cv.imshow`](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563) opens a new window which shows the image we give to it as second argument, the first one is only the name which will be shown about the window.\n",
    "\n",
    "[`cv.waitKey`](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7) blocks the code execution until the user presses a keyboard's button.\n",
    "\n",
    "[`cv.destroyAllWindows`](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga6b7fc1c1a8960438156912027b38f481) destroys all the windows which had previously been created by opencv.\n",
    "\n",
    "*n.b. the command `cv.imshow` above is commented out because on `Jupyter` this makes it crash*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Un)luckily we are using a Jupyter notebook, and the window shown is not convenient.\n",
    "\n",
    "To solve it we can use the library [`matplotlib`](https://matplotlib.org/) of the project [`SciPy`](https://www.scipy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "# without this we will see ticks like in a graph\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.title(\"Example image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the result is the same, but there is a small difference.\n",
    "\n",
    "In the code we spot [`cv.cvtColor`](https://docs.opencv.org/4.3.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab). It converts the image from an encoding to another one.\n",
    "\n",
    "As we have already said, an image (without any compression) is only a matrix of pixels, each pixel is composed by one or more numbers which determine its color. Often, the pixels are composed by three values **R**ed **G**reen and **B**lue (in this order), this is the codification that is used by `matplotlib`.\n",
    "\n",
    "`OpenCV` uses as default the encoding **B**lue **G**reen **R**ed. Why? Because of reasons; Intel's guys are funny people ðŸ¤—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, is_bgr=True):\n",
    "    if(is_bgr):\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined `show` function so, for the rest of the file, we can use it to visualize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "      \n",
    "show(img_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the image to gray scale, then we showed it with our custom function `show`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we can also save an image after we have done some edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(\"./images/example_b.jpg\", img_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv.imwrite` requires two arguments, first the path of the file we want to create, second the image we want to save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color model and color matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to understand what is a color model, and how the one we are currently using works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [`color model`](https://en.wikipedia.org/wiki/Color_model) is a mathematical representation of a [`color space`](https://en.wikipedia.org/wiki/Color_space).\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/RGB_color_solid_cube.png/640px-RGB_color_solid_cube.png\" width=\"300\"/>\n",
    "\n",
    "*Credits [Wikimedia](https://commons.wikimedia.org/wiki/File:RGB_color_solid_cube.png) / SharkD / [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0)*\n",
    "\n",
    "This is a 3D graph of the **RGB** model. Each axes corresponding to a number, so we need three values to identify a single color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw the main function to manipulate the color is `cv.cvtColor`, which allows us to change the color model of the image.\n",
    "\n",
    "Well, but why should we need it? Is our smart **BGR** color representation not sufficient to do everything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://static.poul.org/talks/python/2020/yes_but_no.jpg\" alt=\"yes but actually no\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 435\n",
    "y = 440\n",
    "dx = 20\n",
    "dy = 20\n",
    "\n",
    "img_detail = img[y:y+dy, x:x+dx]\n",
    "\n",
    "show(img_detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an image's detail of the `Craspedia globosa`\\*.\n",
    "\n",
    "(\\*) *talk to your trusted botanical expert*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_min, b_max, _, _ = cv.minMaxLoc(img_detail[:, :, 0])\n",
    "g_min, g_max, _, _ = cv.minMaxLoc(img_detail[:, :, 1])\n",
    "r_min, r_max, _, _ = cv.minMaxLoc(img_detail[:, :, 2])\n",
    "\n",
    "(b_min, b_max), (g_min, g_max), (r_min, r_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With [`cv.minMaxLoc`](https://docs.opencv.org/4.3.0/d2/de8/group__core__array.html#gab473bf2eb6d14ff97e89b355dac20707) we can get the range values of an image's channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b_max-b_min) * (g_max-g_min) * (r_max-r_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the range of components is very wide, although we are just talking about yellow.\n",
    "\n",
    "Let's not worry about that and try to use this information to find the yellow element in the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bgr_lower = np.array([b_min, g_min, r_min], dtype=\"uint8\")\n",
    "bgr_upper = np.array([b_max, g_max, r_max], dtype=\"uint8\")\n",
    "\n",
    "bgr_mask = cv.inRange(img, bgr_lower, bgr_upper)\n",
    "\n",
    "show(bgr_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the best of the results.\n",
    "\n",
    "But what have we done?\n",
    "We defined two color boundaries based on the range discovered above, and with the function `cv.inRange` we generated a mask of the pixels which are in that range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to consider a new color reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/16/Hsl-hsv_models_b.svg\" width=\"500\"/>\n",
    "\n",
    "*Credits [Wikimedia](https://commons.wikimedia.org/wiki/File:Hsl-hsv_models_b.svg) / Jacob Rus, SharkD / [CC BY-SA](https://creativecommons.org/licenses/by-sa/3.0)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **HSL** and **HSV** are two alternatives to **RGB**.\n",
    "\n",
    "Let's retry with one of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detail_hsv = cv.cvtColor(img_detail, cv.COLOR_BGR2HSV)\n",
    "\n",
    "h_min, h_max, _, _ = cv.minMaxLoc(img_detail_hsv[:, :, 0])\n",
    "s_min, s_max, _, _ = cv.minMaxLoc(img_detail_hsv[:, :, 1])\n",
    "v_min, v_max, _, _ = cv.minMaxLoc(img_detail_hsv[:, :, 2])\n",
    "\n",
    "(h_min, h_max), (s_min, s_max), (v_min, v_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_max-h_min) * (s_max-s_min) * (v_max-v_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of colors is much smaller than the previous one.\n",
    "\n",
    "So, retry to find the yellow element now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "hsv_lower = np.array([h_min, s_min, v_min], dtype=\"uint8\")\n",
    "hsv_upper = np.array([h_max, s_max, v_max], dtype=\"uint8\")\n",
    "\n",
    "hsv_mask = cv.inRange(img_hsv, hsv_lower, hsv_upper)\n",
    "\n",
    "show(hsv_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving aside the small blobs the result is rather perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With easy systems of color matching it is preferred to use **HSL** or **HSV** rather than **RGB**.\n",
    "\n",
    "*n.b. between **HSL**, **HSV** and **RGB** there is a one-to-one correspondence, so there is not information loss in conversion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in all measure systems it is a smart idea to remove the noise as soon as possible, when our system contains as much information as possible\\*.\n",
    "\n",
    "(\\*) *talk to your trusted electronic engineer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case this suggests us that we should have removed the reasons of the small blob before applying the `cv.inRange` function, with which we lost most of the image's information.\n",
    "\n",
    "But, maybe this time we can correct it even with considerable information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(hsv_mask, \n",
    "                              cv.RETR_CCOMP,\n",
    "                              cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "hsv_mask_c = cv.cvtColor(hsv_mask, cv.COLOR_GRAY2BGR)\n",
    "hsv_mask_c = cv.drawContours(hsv_mask_c, contours, -1, (0, 0, 255), 3)\n",
    "\n",
    "show(hsv_mask_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `cv.findContours` takes into account a bitmap and returns a list of blob's contours.\n",
    "\n",
    "`cv.drawContours` draws a list of contours on an image. The second argument is the list of contours, the third one is the position in array of the contours we want to draw (`-1` means \"all\"), the fourth one is the \"color\" of contour and the last one is the size of the contour (`-1` means \"fill the contour\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area = 200\n",
    "\n",
    "valid_blobs = list(filter(lambda c: cv.contourArea(c) >= min_area, contours))\n",
    "\n",
    "hsv_mask_c = cv.cvtColor(hsv_mask, cv.COLOR_GRAY2BGR)\n",
    "hsv_mask_c = cv.drawContours(hsv_mask_c, valid_blobs, -1, (0, 0, 255), 3)\n",
    "\n",
    "show(hsv_mask_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With a simple filter on contours' list we have separated valid blobs from false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filtered = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "\n",
    "mask_filtered = cv.drawContours(mask_filtered, valid_blobs, -1, 255, -1)\n",
    "\n",
    "show(mask_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! The mask is perfect now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The circle as basis of everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see now another recurrent technique used in computer vision.\n",
    "\n",
    "Finding particular shapes is a recurrent problem in computer vision.\n",
    "\n",
    "Today, we will see only an easy function to find circles in our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 430\n",
    "y = 270\n",
    "dx = 130\n",
    "dy = 80\n",
    "\n",
    "img_detail = img[y:y+dy, x:x+dx]\n",
    "\n",
    "show(img_detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another detail of the original image. We will try to find the circular shapes.\n",
    "\n",
    "...yes like in a famous children's cartoon... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detail_gray = cv.cvtColor(img_detail, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv.HoughCircles(img_detail_gray, cv.HOUGH_GRADIENT,\n",
    "                          dp=1, minDist=10,\n",
    "                          param1=75, param2=30,\n",
    "                          minRadius=5, maxRadius=50)\n",
    "\n",
    "circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`cv.HoughCircles`](https://docs.opencv.org/4.3.0/dd/d1a/group__imgproc__feature.html#ga47849c3be0d0406ad3ca45db65a25d2d) is a function which exploits the [`Hough transform`](https://en.wikipedia.org/wiki/Hough_transform) to find the circular pattern in the image.\n",
    "\n",
    "In order to work this function needs one channel image, so we have converted the image to grayscale.\n",
    "\n",
    "The function returns an array containing the list of found circles, with `x` and `y` coordinates of center and the `radius`.\n",
    "\n",
    "Less `minDist`, `minRadius` and `maxRadius` which are pretty clear, `dp`, `param1` and `param2`are not intuitive, and they are heavily related to the `Hough transform` theory, that I will not explain to you... because I do not know it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_circles = img_detail.copy()\n",
    "\n",
    "circles_round = np.around(circles[0])\n",
    "circles_int = np.uint16(circles_round)\n",
    "\n",
    "for x, y, r in circles_int:\n",
    "    cv.circle(img_circles,(x,y),r,(0,255,0),2)\n",
    "\n",
    "show(img_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously(?!) the result is terrible.\n",
    "\n",
    "Before going on, let's understand what we have done.\n",
    "\n",
    "With `.copy()` method on `NumPy` array we created a copy of it.\n",
    "\n",
    "The circles list is provided in float format, but the image pixels are identified by integer coordinates, so before we apply a rounding of the matrix `np.around` we convert it to an integer notation `np.uint16`.\n",
    "\n",
    "The function [`cv.circle`](https://docs.opencv.org/4.3.0/d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670) draws a circle on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to get a better result.\n",
    "\n",
    "As we have already said before, to do any operation on an image it is a smart idea to filter as much noise as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detail_blur = cv.medianBlur(img_detail,7)\n",
    "img_detail_blur_gray = cv.cvtColor(img_detail_blur,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "show(img_detail_blur_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median blur filter is a great filter to remove noise from an image.\n",
    "\n",
    "The function [`cv.medianBlur`](https://docs.opencv.org/4.3.0/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9) requires the dimension of the kernel which will be used to create the blur effect.\n",
    "\n",
    "For dummies, the bigger the kernel size the more the losses of the image's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = cv.HoughCircles(img_detail_blur_gray, cv.HOUGH_GRADIENT,\n",
    "                          dp=1, minDist=10,\n",
    "                          param1=75, param2=30,\n",
    "                          minRadius=5, maxRadius=50)\n",
    "\n",
    "img_circles = img_detail.copy()\n",
    "\n",
    "for x, y, r in np.uint16(np.around(circles[0])):\n",
    "    cv.circle(img_circles, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "show(img_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a simple blur filter has been sufficient to solve our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-size:1.6em;\">Thank you!</h1>\n",
    "\n",
    "<p style=\"text-align:center; width:50%; margin: 20px auto;\">And a special thanks to <strong>Francesca</strong> for the amazing work done in the slides correction, thanks to <strong>Lero</strong>, <strong>Ale</strong> and <strong>Fil</strong> for the work done to prepare this course and thanks to who taught me what is a <em>Craspedia globosa</em></p>\n",
    "\n",
    "<img style=\"width: 6em;\" src=\"https://static.poul.org/assets/logo/logo_g.svg\" alt=\"POuL logo\">\n",
    "\n",
    "<p style=\"width: 100%; text-align: center; font-size: 0.7em;\">Licensed under Creative Commons<br/>Attribution-NonCommercial-ShareAlike 4.0 International</p>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a>\n",
    "\n",
    "<p style=\"text-align: center;\">Roberto Bochet &lt;avrdudo@poul.org&gt;</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
